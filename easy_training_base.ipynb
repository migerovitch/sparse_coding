{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import argparse\n",
    "from utils import dotdict\n",
    "from activation_dataset import setup_token_data\n",
    "import wandb\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from baukit import Trace, TraceDict\n",
    "\n",
    "\n",
    "\n",
    "def init_cfg():\n",
    "    cfg = dotdict()\n",
    "    # models: \"EleutherAI/pythia-6.9b\", \"lomahony/eleuther-pythia6.9b-hh-sft\", \"usvsnsp/pythia-6.9b-ppo\", \"Dahoas/gptj-rm-static\", \"reciprocate/dahoas-gptj-rm-static\"\n",
    "    # cfg.model_name=\"lomahony/eleuther-pythia6.9b-hh-sft\"\n",
    "    # \"EleutherAI/pythia-70m\", \"lomahony/pythia-70m-helpful-sft\", \"lomahony/eleuther-pythia70m-hh-sft\"\n",
    "    cfg.model_name=\"EleutherAI/pythia-70m-deduped\"\n",
    "    cfg.layers=[0, 1] # Change this to run multiple layers\n",
    "    cfg.setting=\"residual\"\n",
    "    # cfg.tensor_name=\"gpt_neox.layers.{layer}\" or \"transformer.h.{layer}\"\n",
    "    cfg.tensor_name=\"gpt_neox.layers.{layer}.mlp\"\n",
    "    original_l1_alpha = 8e-4\n",
    "    cfg.l1_alpha=original_l1_alpha\n",
    "    cfg.l1_alphas=[8e-5, 1e-4, 2e-4, 4e-4, 8e-4, 1e-3, 2e-3, 4e-3, 8e-3]\n",
    "    cfg.sparsity=None\n",
    "    cfg.num_epochs=2\n",
    "    cfg.model_batch_size=8\n",
    "    cfg.lr=1e-3 # ORIGINAL: 1e-3\n",
    "    cfg.kl=False\n",
    "    cfg.reconstruction=False\n",
    "    #cfg.dataset_name=\"NeelNanda/pile-10k\"\n",
    "    cfg.dataset_name=\"Elriggs/openwebtext-100k\"\n",
    "    cfg.device=\"cuda:0\"\n",
    "    cfg.ratio = 8\n",
    "    cfg.seed = 0\n",
    "    # cfg.device=\"cpu\"\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_execute_training(model_name,\n",
    "                          dataset_name,\n",
    "                          ratio,\n",
    "                          layers,\n",
    "                          seed,\n",
    "                          wandb_log,\n",
    "                          split,\n",
    "                          epoches):\n",
    "    cfg = init_cfg()\n",
    "    cfg.num_epoches = epoches\n",
    "    cfg.model_name = model_name\n",
    "    cfg.dataset_name = dataset_name\n",
    "    cfg.ratio = ratio\n",
    "    cfg.layers = layers\n",
    "    cfg.seed = seed\n",
    "    cfg.wandb_log = wandb_log\n",
    "\n",
    "    model, tokenizer = load_model(cfg)\n",
    "    get_activation_size(cfg, model, tokenizer)\n",
    "\n",
    "    # naming\n",
    "    start_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    wandb_run_name = f\"{cfg.model_name}_{cfg.dataset_name}_s{cfg.seed}_dim{cfg.ratio*cfg.activation_size}_{start_time[4:]}\"\n",
    "    model_name_path = cfg.model_name.replace(\"/\", \"_\")\n",
    "    dataset_name_path = cfg.dataset_name.split(\"/\")[-1]\n",
    "    storage_path = f\"{model_name_path}/{dataset_name_path}_s{cfg.seed}\"\n",
    "    filename = f\"{cfg.ratio*cfg.activation_size}_{start_time[4:]}\"\n",
    "    token_loader = init_dataloader(cfg, model, tokenizer, split)\n",
    "    autoencoders, optimizers = init_autoencoder(cfg)\n",
    "    \n",
    "    if wandb_log:\n",
    "        setup_wandb(cfg, wandb_run_name)\n",
    "    \n",
    "    training_run(cfg, model, optimizers, autoencoders, token_loader)\n",
    "\n",
    "    for layer in range(len(cfg.layers)):\n",
    "        model_save(cfg, autoencoders[layer], storage_path, filename, cfg.layers[layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation size: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-f0c48232d0cb60cb_*_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 112750592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55054 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 12321.4 | Dead Features: 24576 | Total Loss: 0.7348 | Reconstruction Loss: 0.1742 | L1 Loss: 0.5607 | l1_alpha: 8.0000e-04 | Tokens: 0 | Self Similarity: 1.0000\n",
      "Sparsity: 12315.4 | Dead Features: 24576 | Total Loss: 0.3584 | Reconstruction Loss: 0.0555 | L1 Loss: 0.3029 | l1_alpha: 8.0000e-04 | Tokens: 0 | Self Similarity: -0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/55054 [00:00<3:52:44,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 12254.1 | Dead Features: 24576 | Total Loss: 0.6150 | Reconstruction Loss: 0.1848 | L1 Loss: 0.4302 | l1_alpha: 8.0000e-04 | Tokens: 0 | Self Similarity: -0.0001\n",
      "Sparsity: 12276.1 | Dead Features: 24576 | Total Loss: 1.5557 | Reconstruction Loss: 1.0040 | L1 Loss: 0.5517 | l1_alpha: 8.0000e-04 | Tokens: 0 | Self Similarity: 0.0003\n",
      "Sparsity: 12315.4 | Dead Features: 24576 | Total Loss: 0.6045 | Reconstruction Loss: 0.1241 | L1 Loss: 0.4804 | l1_alpha: 8.0000e-04 | Tokens: 0 | Self Similarity: -0.0002\n",
      "Sparsity: 12296.9 | Dead Features: 24576 | Total Loss: 0.7907 | Reconstruction Loss: 0.1979 | L1 Loss: 0.5928 | l1_alpha: 8.0000e-04 | Tokens: 0 | Self Similarity: -0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 101/55054 [00:15<2:23:24,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 16.9 | Dead Features: 0 | Total Loss: 0.0582 | Reconstruction Loss: 0.0534 | L1 Loss: 0.0048 | l1_alpha: 8.0000e-04 | Tokens: 204800 | Self Similarity: -0.0000\n",
      "Sparsity: 4.4 | Dead Features: 0 | Total Loss: 0.0201 | Reconstruction Loss: 0.0181 | L1 Loss: 0.0020 | l1_alpha: 8.0000e-04 | Tokens: 204800 | Self Similarity: -0.0002\n",
      "Sparsity: 22.9 | Dead Features: 0 | Total Loss: 0.0426 | Reconstruction Loss: 0.0393 | L1 Loss: 0.0033 | l1_alpha: 8.0000e-04 | Tokens: 204800 | Self Similarity: 0.0230\n",
      "Sparsity: 78.9 | Dead Features: 0 | Total Loss: 0.0591 | Reconstruction Loss: 0.0462 | L1 Loss: 0.0129 | l1_alpha: 8.0000e-04 | Tokens: 204800 | Self Similarity: -0.0756\n",
      "Sparsity: 8.8 | Dead Features: 0 | Total Loss: 0.0521 | Reconstruction Loss: 0.0487 | L1 Loss: 0.0034 | l1_alpha: 8.0000e-04 | Tokens: 204800 | Self Similarity: 0.0290\n",
      "Sparsity: 43.2 | Dead Features: 0 | Total Loss: 0.0606 | Reconstruction Loss: 0.0529 | L1 Loss: 0.0077 | l1_alpha: 8.0000e-04 | Tokens: 204800 | Self Similarity: -0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 201/55054 [00:30<2:28:38,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 18.1 | Dead Features: 0 | Total Loss: 0.0474 | Reconstruction Loss: 0.0414 | L1 Loss: 0.0060 | l1_alpha: 8.0000e-04 | Tokens: 409600 | Self Similarity: 0.0031\n",
      "Sparsity: 4.5 | Dead Features: 0 | Total Loss: 0.0188 | Reconstruction Loss: 0.0166 | L1 Loss: 0.0021 | l1_alpha: 8.0000e-04 | Tokens: 409600 | Self Similarity: -0.0082\n",
      "Sparsity: 13.4 | Dead Features: 0 | Total Loss: 0.0375 | Reconstruction Loss: 0.0343 | L1 Loss: 0.0033 | l1_alpha: 8.0000e-04 | Tokens: 409600 | Self Similarity: 0.0244\n",
      "Sparsity: 25.5 | Dead Features: 0 | Total Loss: 0.0465 | Reconstruction Loss: 0.0386 | L1 Loss: 0.0079 | l1_alpha: 8.0000e-04 | Tokens: 409600 | Self Similarity: -0.0752\n",
      "Sparsity: 11.1 | Dead Features: 0 | Total Loss: 0.0482 | Reconstruction Loss: 0.0438 | L1 Loss: 0.0044 | l1_alpha: 8.0000e-04 | Tokens: 409600 | Self Similarity: 0.0297\n",
      "Sparsity: 24.4 | Dead Features: 0 | Total Loss: 0.0543 | Reconstruction Loss: 0.0467 | L1 Loss: 0.0076 | l1_alpha: 8.0000e-04 | Tokens: 409600 | Self Similarity: -0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 301/55054 [00:46<2:21:20,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 19.1 | Dead Features: 0 | Total Loss: 0.0420 | Reconstruction Loss: 0.0351 | L1 Loss: 0.0069 | l1_alpha: 8.0000e-04 | Tokens: 614400 | Self Similarity: 0.0038\n",
      "Sparsity: 9.3 | Dead Features: 0 | Total Loss: 0.0198 | Reconstruction Loss: 0.0174 | L1 Loss: 0.0024 | l1_alpha: 8.0000e-04 | Tokens: 614400 | Self Similarity: -0.0087\n",
      "Sparsity: 16.3 | Dead Features: 0 | Total Loss: 0.0372 | Reconstruction Loss: 0.0334 | L1 Loss: 0.0038 | l1_alpha: 8.0000e-04 | Tokens: 614400 | Self Similarity: 0.0267\n",
      "Sparsity: 29.4 | Dead Features: 0 | Total Loss: 0.0435 | Reconstruction Loss: 0.0374 | L1 Loss: 0.0061 | l1_alpha: 8.0000e-04 | Tokens: 614400 | Self Similarity: -0.0745\n",
      "Sparsity: 14.7 | Dead Features: 0 | Total Loss: 0.0472 | Reconstruction Loss: 0.0422 | L1 Loss: 0.0050 | l1_alpha: 8.0000e-04 | Tokens: 614400 | Self Similarity: 0.0308\n",
      "Sparsity: 23.5 | Dead Features: 0 | Total Loss: 0.0525 | Reconstruction Loss: 0.0444 | L1 Loss: 0.0081 | l1_alpha: 8.0000e-04 | Tokens: 614400 | Self Similarity: -0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 401/55054 [01:01<2:23:20,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 21.2 | Dead Features: 0 | Total Loss: 0.0386 | Reconstruction Loss: 0.0311 | L1 Loss: 0.0075 | l1_alpha: 8.0000e-04 | Tokens: 819200 | Self Similarity: 0.0034\n",
      "Sparsity: 8.0 | Dead Features: 0 | Total Loss: 0.0186 | Reconstruction Loss: 0.0160 | L1 Loss: 0.0026 | l1_alpha: 8.0000e-04 | Tokens: 819200 | Self Similarity: -0.0097\n",
      "Sparsity: 18.0 | Dead Features: 0 | Total Loss: 0.0359 | Reconstruction Loss: 0.0316 | L1 Loss: 0.0043 | l1_alpha: 8.0000e-04 | Tokens: 819200 | Self Similarity: 0.0260\n",
      "Sparsity: 40.4 | Dead Features: 0 | Total Loss: 0.0429 | Reconstruction Loss: 0.0364 | L1 Loss: 0.0065 | l1_alpha: 8.0000e-04 | Tokens: 819200 | Self Similarity: -0.0745\n",
      "Sparsity: 16.0 | Dead Features: 0 | Total Loss: 0.0471 | Reconstruction Loss: 0.0416 | L1 Loss: 0.0055 | l1_alpha: 8.0000e-04 | Tokens: 819200 | Self Similarity: 0.0315\n",
      "Sparsity: 25.0 | Dead Features: 0 | Total Loss: 0.0522 | Reconstruction Loss: 0.0433 | L1 Loss: 0.0089 | l1_alpha: 8.0000e-04 | Tokens: 819200 | Self Similarity: -0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 501/55054 [01:17<2:21:44,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 27.6 | Dead Features: 0 | Total Loss: 0.0363 | Reconstruction Loss: 0.0281 | L1 Loss: 0.0082 | l1_alpha: 8.0000e-04 | Tokens: 1024000 | Self Similarity: 0.0028\n",
      "Sparsity: 10.7 | Dead Features: 0 | Total Loss: 0.0181 | Reconstruction Loss: 0.0154 | L1 Loss: 0.0027 | l1_alpha: 8.0000e-04 | Tokens: 1024000 | Self Similarity: -0.0109\n",
      "Sparsity: 20.7 | Dead Features: 0 | Total Loss: 0.0347 | Reconstruction Loss: 0.0298 | L1 Loss: 0.0048 | l1_alpha: 8.0000e-04 | Tokens: 1024000 | Self Similarity: 0.0111\n",
      "Sparsity: 28.5 | Dead Features: 0 | Total Loss: 0.0407 | Reconstruction Loss: 0.0342 | L1 Loss: 0.0065 | l1_alpha: 8.0000e-04 | Tokens: 1024000 | Self Similarity: -0.0834\n",
      "Sparsity: 20.1 | Dead Features: 0 | Total Loss: 0.0459 | Reconstruction Loss: 0.0396 | L1 Loss: 0.0063 | l1_alpha: 8.0000e-04 | Tokens: 1024000 | Self Similarity: 0.0376\n",
      "Sparsity: 25.7 | Dead Features: 0 | Total Loss: 0.0521 | Reconstruction Loss: 0.0429 | L1 Loss: 0.0092 | l1_alpha: 8.0000e-04 | Tokens: 1024000 | Self Similarity: -0.0276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 601/55054 [01:32<2:21:46,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 30.5 | Dead Features: 0 | Total Loss: 0.0368 | Reconstruction Loss: 0.0281 | L1 Loss: 0.0088 | l1_alpha: 8.0000e-04 | Tokens: 1228800 | Self Similarity: 0.0028\n",
      "Sparsity: 12.6 | Dead Features: 0 | Total Loss: 0.0179 | Reconstruction Loss: 0.0152 | L1 Loss: 0.0028 | l1_alpha: 8.0000e-04 | Tokens: 1228800 | Self Similarity: -0.0119\n",
      "Sparsity: 22.6 | Dead Features: 0 | Total Loss: 0.0355 | Reconstruction Loss: 0.0303 | L1 Loss: 0.0052 | l1_alpha: 8.0000e-04 | Tokens: 1228800 | Self Similarity: 0.0108\n",
      "Sparsity: 31.6 | Dead Features: 0 | Total Loss: 0.0403 | Reconstruction Loss: 0.0336 | L1 Loss: 0.0067 | l1_alpha: 8.0000e-04 | Tokens: 1228800 | Self Similarity: -0.0843\n",
      "Sparsity: 23.2 | Dead Features: 0 | Total Loss: 0.0455 | Reconstruction Loss: 0.0384 | L1 Loss: 0.0070 | l1_alpha: 8.0000e-04 | Tokens: 1228800 | Self Similarity: 0.0376\n",
      "Sparsity: 27.9 | Dead Features: 0 | Total Loss: 0.0529 | Reconstruction Loss: 0.0435 | L1 Loss: 0.0094 | l1_alpha: 8.0000e-04 | Tokens: 1228800 | Self Similarity: -0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 618/55054 [01:35<2:18:40,  6.54it/s]"
     ]
    }
   ],
   "source": [
    "# Code that actually starts a full training run!\n",
    "\n",
    "model_name = \"EleutherAI/pythia-160m\"\n",
    "dataset_name = \"Elriggs/openwebtext-100k\" # \"Elriggs/openwebtext-100k\"\n",
    "ratio = 32\n",
    "layers = [0, 1, 2, 3, 4, 5]\n",
    "wandb_log = False\n",
    "seed = 0\n",
    "split = \"train\"\n",
    "epoches = 1\n",
    "\n",
    "setup_execute_training(model_name,\n",
    "                       dataset_name,\n",
    "                       ratio,\n",
    "                       layers,\n",
    "                       seed,\n",
    "                       wandb_log=wandb_log,\n",
    "                       split=split,\n",
    "                      epoches=epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code that actually starts a full training run!\n",
    "\n",
    "model_name = \"EleutherAI/pythia-160m\"\n",
    "dataset_name = \"Elriggs/openwebtext-100k\" # \"Elriggs/openwebtext-100k\"\n",
    "ratio = 16\n",
    "layers = [0, 1, 2, 3, 4, 5]\n",
    "wandb_log = False\n",
    "seed = 0\n",
    "split = \"train\"\n",
    "epoches = 1\n",
    "\n",
    "setup_execute_training(model_name,\n",
    "                       dataset_name,\n",
    "                       ratio,\n",
    "                       layers,\n",
    "                       seed,\n",
    "                       wandb_log=wandb_log,\n",
    "                       split=split,\n",
    "                      epoches=epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code that actually starts a full training run!\n",
    "\n",
    "model_name = \"EleutherAI/pythia-160m\"\n",
    "dataset_name = \"Elriggs/openwebtext-100k\" # \"Elriggs/openwebtext-100k\"\n",
    "ratio = 2\n",
    "layers = [0, 1, 2, 3, 4, 5]\n",
    "wandb_log = False\n",
    "seed = 0\n",
    "split = \"train\"\n",
    "epoches = 1\n",
    "\n",
    "setup_execute_training(model_name,\n",
    "                       dataset_name,\n",
    "                       ratio,\n",
    "                       layers,\n",
    "                       seed,\n",
    "                       wandb_log=wandb_log,\n",
    "                       split=split,\n",
    "                      epoches=epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code that actually starts a full training run!\n",
    "\n",
    "model_name = \"EleutherAI/pythia-70m\"\n",
    "dataset_name = \"Elriggs/openwebtext-100k\" # \"Elriggs/openwebtext-100k\"\n",
    "ratio = 2\n",
    "layers = [0, 1, 2, 3, 4, 5]\n",
    "wandb_log = False\n",
    "seed = 0\n",
    "split = \"train\"\n",
    "epoches = 1\n",
    "\n",
    "setup_execute_training(model_name,\n",
    "                       dataset_name,\n",
    "                       ratio,\n",
    "                       layers,\n",
    "                       seed,\n",
    "                       wandb_log=wandb_log,\n",
    "                       split=split,\n",
    "                      epoches=epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code that actually starts a full training run!\n",
    "\n",
    "model_name = \"EleutherAI/pythia-70m\"\n",
    "dataset_name = \"Elriggs/openwebtext-100k\" # \"Elriggs/openwebtext-100k\"\n",
    "ratio = 8\n",
    "layers = [0, 1, 2, 3, 4, 5]\n",
    "wandb_log = False\n",
    "seed = 0\n",
    "split = \"train\"\n",
    "epoches = 1\n",
    "\n",
    "setup_execute_training(model_name,\n",
    "                       dataset_name,\n",
    "                       ratio,\n",
    "                       layers,\n",
    "                       seed,\n",
    "                       wandb_log=wandb_log,\n",
    "                       split=split,\n",
    "                      epoches=epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code that actually starts a full training run!\n",
    "\n",
    "model_name = \"EleutherAI/pythia-70m\"\n",
    "dataset_name = \"Elriggs/openwebtext-100k\" # \"Elriggs/openwebtext-100k\"\n",
    "ratio = 4\n",
    "layers = [0, 1, 2, 3, 4, 5]\n",
    "wandb_log = False\n",
    "seed = 0\n",
    "split = \"train[:50000]\"\n",
    "epoches = 1\n",
    "\n",
    "setup_execute_training(model_name,\n",
    "                       dataset_name,\n",
    "                       ratio,\n",
    "                       layers,\n",
    "                       seed,\n",
    "                       wandb_log=wandb_log,\n",
    "                       split=split,\n",
    "                      epoches=epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code that actually starts a full training run!\n",
    "\n",
    "model_name = \"EleutherAI/pythia-70m\"\n",
    "dataset_name = \"Elriggs/openwebtext-100k\" # \"Elriggs/openwebtext-100k\"\n",
    "ratio = 4\n",
    "layers = [0, 1, 2, 3, 4, 5]\n",
    "wandb_log = False\n",
    "seed = 0\n",
    "split = \"train[50000:]\"\n",
    "epoches = 1\n",
    "\n",
    "setup_execute_training(model_name,\n",
    "                       dataset_name,\n",
    "                       ratio,\n",
    "                       layers,\n",
    "                       seed,\n",
    "                       wandb_log=wandb_log,\n",
    "                       split=split,\n",
    "                      epoches=epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code that actually starts a full training run!\n",
    "\n",
    "model_name = \"EleutherAI/pythia-160m\"\n",
    "dataset_name = \"Elriggs/openwebtext-100k\" # \"Elriggs/openwebtext-100k\"\n",
    "ratio = 4\n",
    "layers = [0, 1, 2, 3, 4, 5]\n",
    "wandb_log = False\n",
    "seed = 0\n",
    "split = \"train[:50000]\"\n",
    "epoches = 1\n",
    "\n",
    "setup_execute_training(model_name,\n",
    "                       dataset_name,\n",
    "                       ratio,\n",
    "                       layers,\n",
    "                       seed,\n",
    "                       wandb_log=wandb_log,\n",
    "                       split=split,\n",
    "                      epoches=epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code that actually starts a full training run!\n",
    "\n",
    "model_name = \"EleutherAI/pythia-160m\"\n",
    "dataset_name = \"Elriggs/openwebtext-100k\" # \"Elriggs/openwebtext-100k\"\n",
    "ratio = 4\n",
    "layers = [0, 1, 2, 3, 4, 5]\n",
    "wandb_log = False\n",
    "seed = 0\n",
    "split = \"train[50000:]\"\n",
    "epoches = 1\n",
    "\n",
    "setup_execute_training(model_name,\n",
    "                       dataset_name,\n",
    "                       ratio,\n",
    "                       layers,\n",
    "                       seed,\n",
    "                       wandb_log=wandb_log,\n",
    "                       split=split,\n",
    "                      epoches=epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code that actually starts a full training run!\n",
    "\n",
    "model_name = \"EleutherAI/pythia-410m\"\n",
    "dataset_name = \"Elriggs/openwebtext-100k\" # \"Elriggs/openwebtext-100k\"\n",
    "ratio = 2\n",
    "layers = [0, 1, 2, 3, 4, 5]\n",
    "wandb_log = False\n",
    "seed = 0\n",
    "split = \"train\"\n",
    "epoches = 1\n",
    "\n",
    "setup_execute_training(model_name,\n",
    "                       dataset_name,\n",
    "                       ratio,\n",
    "                       layers,\n",
    "                       seed,\n",
    "                       wandb_log=wandb_log,\n",
    "                       split=split,\n",
    "                      epoches=epoches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model + Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification, GPTJForSequenceClassification\n",
    "\n",
    "\n",
    "# Load in the model\n",
    "def load_model(cfg):\n",
    "    model = AutoModelForCausalLM.from_pretrained(cfg.model_name)\n",
    "    model = model.to(cfg.device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "# TODO iteratively grab dataset?\n",
    "def init_dataloader(cfg, model, tokenizer, split=\"train\"):\n",
    "    cfg.max_length = 256\n",
    "    token_loader = setup_token_data(cfg, tokenizer, model, seed=cfg.seed, split=split)\n",
    "    num_tokens = cfg.max_length*cfg.model_batch_size*len(token_loader)\n",
    "    print(f\"Number of tokens: {num_tokens}\")\n",
    "    cfg.total_tokens = num_tokens\n",
    "    \n",
    "    return token_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 1 datapoint on model to get the activation size\n",
    "\n",
    "def get_activation_size(cfg, model, tokenizer):\n",
    "    text = \"1\"\n",
    "    tensor_names = [cfg.tensor_name.format(layer=layer) for layer in cfg.layers]\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\").input_ids.to(cfg.device)\n",
    "    # Your activation name will be different. In the next cells, we will show you how to find it.\n",
    "    with torch.no_grad():\n",
    "        with Trace(model, tensor_names[0]) as ret:\n",
    "            _ = model(tokens)\n",
    "            representation = ret.output\n",
    "            # check if instance tuple\n",
    "            if(isinstance(representation, tuple)):\n",
    "                representation = representation[0]\n",
    "            activation_size = representation.shape[-1]\n",
    "    print(f\"Activation size: {activation_size}\")\n",
    "    cfg.activation_size = activation_size\n",
    "    return activation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(cfg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Your activation name will be different. In the next cells, we will show you how to find it.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# text = \"1\"\n",
    "# tokens = tokenizer(text, return_tensors=\"pt\").input_ids.to(cfg.device)\n",
    "# # Your activation name will be different. In the next cells, we will show you how to find it.\n",
    "# with torch.no_grad():\n",
    "#     with Trace(model, 'gpt_neox.layers.0.mlp') as ret:\n",
    "#         _ = model(tokens)\n",
    "#         representation = ret.output\n",
    "#         # check if instance tuple\n",
    "#         if(isinstance(representation, tuple)):\n",
    "#             representation = representation[0]\n",
    "#         activation_size = representation.shape[-1]\n",
    "# print(f\"Activation size: {activation_size}\")\n",
    "# cfg.activation_size = activation_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set target sparsity to 10% of activation_size if not set\n",
    "\n",
    "# # NOT USED\n",
    "# if cfg.sparsity is None:\n",
    "#     cfg.sparsity = int(activation_size*0.05)\n",
    "#     print(f\"Target sparsity: {cfg.sparsity}\")\n",
    "\n",
    "# target_lower_sparsity = cfg.sparsity * 0.9\n",
    "# target_upper_sparsity = cfg.sparsity * 1.1\n",
    "# adjustment_factor = 0.1  # You can set this to whatever you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Autoencocer init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_autoencoder(cfg):\n",
    "    autoencoders = []\n",
    "    optimizers = []\n",
    "    for layer in range(len(cfg.layers)):\n",
    "        params = dict()\n",
    "        n_dict_components = cfg.activation_size*cfg.ratio # Sparse Autoencoder Size\n",
    "        params[\"encoder\"] = torch.empty((n_dict_components, cfg.activation_size), device=cfg.device)\n",
    "        nn.init.xavier_uniform_(params[\"encoder\"])\n",
    "    \n",
    "        params[\"decoder\"] = torch.empty((n_dict_components, cfg.activation_size), device=cfg.device)\n",
    "        nn.init.xavier_uniform_(params[\"decoder\"])\n",
    "    \n",
    "        params[\"encoder_bias\"] = torch.empty((n_dict_components,), device=cfg.device)\n",
    "        nn.init.zeros_(params[\"encoder_bias\"])\n",
    "    \n",
    "        params[\"shift_bias\"] = torch.empty((cfg.activation_size,), device=cfg.device)\n",
    "        nn.init.zeros_(params[\"shift_bias\"])\n",
    "    \n",
    "        autoencoder = AnthropicSAE(  # TiedSAE, UntiedSAE, AnthropicSAE\n",
    "            # n_feats = n_dict_components, \n",
    "            # activation_size=cfg.activation_size,\n",
    "            encoder=params[\"encoder\"],\n",
    "            encoder_bias=params[\"encoder_bias\"],\n",
    "            decoder=params[\"decoder\"],\n",
    "            shift_bias=params[\"shift_bias\"],\n",
    "        )\n",
    "        autoencoder.to_device(cfg.device)\n",
    "        autoencoder.set_grad()\n",
    "    \n",
    "        optimizer = torch.optim.Adam(\n",
    "            [\n",
    "                autoencoder.encoder, \n",
    "                autoencoder.encoder_bias,\n",
    "                autoencoder.decoder,\n",
    "                autoencoder.shift_bias,\n",
    "            ], lr=cfg.lr)\n",
    "        autoencoders.append(autoencoder)\n",
    "        optimizers.append(optimizer)\n",
    "    return autoencoders, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_names = ['gpt_neox.layers.0.mlp', 'gpt_neox.layers.5.mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_bias = autoencoder.encoder_bias.clone().detach()\n",
    "# Wandb setup\n",
    "def setup_wandb(cfg, wandb_run_name):\n",
    "    secrets = json.load(open(\"secrets.json\"))\n",
    "    wandb.login(key=secrets[\"wandb_key\"])\n",
    "    wandb.init(project=\"Sparse Coding >70m\", config=dict(cfg), name=wandb_run_name)\n",
    "    return wandb_run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_run(cfg, model, optimizers, autoencoders, token_loader):\n",
    "\n",
    "    time_since_activation = torch.zeros(autoencoders[0].encoder.shape[0])\n",
    "    total_activations = torch.zeros(autoencoders[0].encoder.shape[0])\n",
    "    tensor_names = [cfg.tensor_name.format(layer=layer) for layer in cfg.layers]\n",
    "    max_num_tokens = cfg.total_tokens # 100_000_000\n",
    "    save_every = 30_000\n",
    "    num_saved_so_far = 0\n",
    "\n",
    "    # Freeze model parameters \n",
    "    model.eval()\n",
    "    model.requires_grad_(False)\n",
    "    model.to(cfg.device)\n",
    "    \n",
    "    last_encoder = autoencoders[0].encoder.clone().detach()\n",
    "    assert len(cfg.layers) == len(tensor_names), \"layers and tensor_names have different lengths\"\n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        for i, batch in enumerate(tqdm(token_loader)): #,total=int(max_num_tokens/(cfg.max_length*cfg.model_batch_size)))):\n",
    "            tokens = batch[\"input_ids\"].to(cfg.device)\n",
    "            # print(f\"tokens shape: {tokens.shape}\")\n",
    "            \n",
    "            with torch.no_grad(): # As long as not doing KL divergence, don't need gradients for model\n",
    "                \n",
    "                #print(tensor_names)\n",
    "                representations = []\n",
    "                with TraceDict(model, tensor_names) as ret:\n",
    "                    _ = model(tokens)\n",
    "                    for tensor_name in tensor_names:\n",
    "                        representations.append(ret[tensor_name].output)\n",
    "                    assert not isinstance(representations[0], tuple), \"representations is type tuple\"\n",
    "                    # print(len(representations), representations[0].shape)\n",
    "                    # if(isinstance(representation, tuple)):\n",
    "                    #     representation = representation[0]\n",
    "            #print(f\"representation is: {representation}\")\n",
    "            #print(f\"representation shape is: {representation.shape}\")\n",
    "            \n",
    "        \n",
    "            # activation_saver.save_batch(layer_activations.clone().cpu().detach())\n",
    "            for layer in range(len(cfg.layers)):\n",
    "                representation = representations[layer]\n",
    "                layer_activations = rearrange(representation, \"b seq d_model -> (b seq) d_model\")\n",
    "                autoencoder = autoencoders[layer]\n",
    "                optimizer = optimizers[layer]\n",
    "                \n",
    "                c = autoencoder.encode(layer_activations)\n",
    "                x_hat = autoencoder.decode(c)\n",
    "                \n",
    "                reconstruction_loss = (x_hat - layer_activations).pow(2).mean()\n",
    "                l1_loss = torch.norm(c, 1, dim=-1).mean()\n",
    "                total_loss = reconstruction_loss + cfg.l1_alpha*l1_loss\n",
    "            \n",
    "                time_since_activation += 1\n",
    "                time_since_activation = time_since_activation * (c.sum(dim=0).cpu()==0)\n",
    "                # total_activations += c.sum(dim=0).cpu()\n",
    "                if ((i) % 100 == 0): # Check here so first check is model w/o change\n",
    "                    # self_similarity = torch.cosine_similarity(c, last_encoder, dim=-1).mean().cpu().item()\n",
    "                    # Above is wrong, should be similarity between encoder and last encoder\n",
    "                    self_similarity = torch.cosine_similarity(autoencoder.encoder, last_encoder, dim=-1).mean().cpu().item()\n",
    "                    last_encoder = autoencoder.encoder.clone().detach()\n",
    "            \n",
    "                    num_tokens_so_far = i*cfg.max_length*cfg.model_batch_size\n",
    "                    with torch.no_grad():\n",
    "                        sparsity = (c != 0).float().mean(dim=0).sum().cpu().item()\n",
    "                        # Count number of dead_features are zero\n",
    "                        num_dead_features = (time_since_activation >= min(i, 200)).sum().item()\n",
    "                    print(f\"Sparsity: {sparsity:.1f} | Dead Features: {num_dead_features} | Total Loss: {total_loss:.4f} | Reconstruction Loss: {reconstruction_loss:.4f} | L1 Loss: {cfg.l1_alpha*l1_loss:.4f} | l1_alpha: {cfg.l1_alpha:.4e} | Tokens: {num_tokens_so_far} | Self Similarity: {self_similarity:.4f}\")\n",
    "                    \n",
    "                    if cfg.wandb_log:\n",
    "                        wandb.log({\n",
    "                            'Sparsity': sparsity,\n",
    "                            'Dead Features': num_dead_features,\n",
    "                            'Total Loss': total_loss.item(),\n",
    "                            'Reconstruction Loss': reconstruction_loss.item(),\n",
    "                            'L1 Loss': (cfg.l1_alpha*l1_loss).item(),\n",
    "                            'l1_alpha': cfg.l1_alpha,\n",
    "                            'Tokens': num_tokens_so_far,\n",
    "                            'Self Similarity': self_similarity\n",
    "                        })\n",
    "                    \n",
    "                    dead_features = torch.zeros(autoencoder.encoder.shape[0])\n",
    "                    \n",
    "                    # if(num_tokens_so_far > max_num_tokens):\n",
    "                    #     print(f\"Reached max number of tokens: {max_num_tokens}\")\n",
    "                    #     break\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "    wandb.finish()\n",
    "        # resample_period = 10000\n",
    "        # if (i % resample_period == 0):\n",
    "        #     # RESAMPLING\n",
    "        #     with torch.no_grad():\n",
    "        #         # Count number of dead_features are zero\n",
    "        #         num_dead_features = (total_activations == 0).sum().item()\n",
    "        #         print(f\"Dead Features: {num_dead_features}\")\n",
    "                \n",
    "        #     if num_dead_features > 0:\n",
    "        #         print(\"Resampling!\")\n",
    "        #         # hyperparams:\n",
    "        #         max_resample_tokens = 1000 # the number of token activations that we consider for inserting into the dictionary\n",
    "        #         # compute loss of model on random subset of inputs\n",
    "        #         resample_loader = setup_token_data(cfg, tokenizer, model, seed=i)\n",
    "        #         num_resample_data = 0\n",
    "    \n",
    "        #         resample_activations = torch.empty(0, activation_size)\n",
    "        #         resample_losses = torch.empty(0)\n",
    "    \n",
    "        #         for resample_batch in resample_loader:\n",
    "        #             resample_tokens = resample_batch[\"input_ids\"].to(cfg.device)\n",
    "        #             with torch.no_grad(): # As long as not doing KL divergence, don't need gradients for model\n",
    "        #                 with Trace(model, tensor_names[0]) as ret:\n",
    "        #                     _ = model(resample_tokens)\n",
    "        #                     representation = ret.output\n",
    "        #                     if(isinstance(representation, tuple)):\n",
    "        #                         representation = representation[0]\n",
    "        #             layer_activations = rearrange(representation, \"b seq d_model -> (b seq) d_model\")\n",
    "        #             resample_activations = torch.cat((resample_activations, layer_activations.detach().cpu()), dim=0)\n",
    "    \n",
    "        #             c = autoencoder.encode(layer_activations)\n",
    "        #             x_hat = autoencoder.decode(c)\n",
    "                    \n",
    "        #             reconstruction_loss = (x_hat - layer_activations).pow(2).mean(dim=-1)\n",
    "        #             l1_loss = torch.norm(c, 1, dim=-1)\n",
    "        #             temp_loss = reconstruction_loss + cfg.l1_alpha*l1_loss\n",
    "                    \n",
    "        #             resample_losses = torch.cat((resample_losses, temp_loss.detach().cpu()), dim=0)\n",
    "                    \n",
    "        #             num_resample_data +=layer_activations.shape[0]\n",
    "        #             if num_resample_data > max_resample_tokens:\n",
    "        #                 break\n",
    "    \n",
    "                    \n",
    "        #         # sample num_dead_features vectors of input activations\n",
    "        #         probabilities = resample_losses**2\n",
    "        #         probabilities /= probabilities.sum()\n",
    "        #         sampled_indices = torch.multinomial(probabilities, num_dead_features, replacement=True)\n",
    "        #         new_vectors = resample_activations[sampled_indices]\n",
    "    \n",
    "        #         # calculate average encoder norm of alive neurons\n",
    "        #         alive_neurons = list((total_activations!=0))\n",
    "        #         modified_columns = total_activations==0\n",
    "        #         avg_norm = autoencoder.encoder.data[alive_neurons].norm(dim=-1).mean()\n",
    "    \n",
    "        #         # replace dictionary and encoder weights with vectors\n",
    "        #         new_vectors = new_vectors / new_vectors.norm(dim=1, keepdim=True)\n",
    "                \n",
    "        #         params_to_modify = [autoencoder.encoder, autoencoder.encoder_bias]\n",
    "    \n",
    "        #         current_weights = autoencoder.encoder.data\n",
    "        #         current_weights[modified_columns] = (new_vectors.to(cfg.device) * avg_norm * 0.02)\n",
    "        #         autoencoder.encoder.data = current_weights\n",
    "    \n",
    "        #         current_weights = autoencoder.encoder_bias.data\n",
    "        #         current_weights[modified_columns] = 0\n",
    "        #         autoencoder.encoder_bias.data = current_weights\n",
    "                \n",
    "        #         if hasattr(autoencoder, 'decoder'):\n",
    "        #             current_weights = autoencoder.decoder.data\n",
    "        #             current_weights[modified_columns] = new_vectors.to(cfg.device)\n",
    "        #             autoencoder.decoder.data = current_weights\n",
    "        #             params_to_modify += [autoencoder.decoder]\n",
    "    \n",
    "        #         for param_group in optimizer.param_groups:\n",
    "        #             for param in param_group['params']:\n",
    "        #                 if any(param is d_ for d_ in params_to_modify):\n",
    "        #                     # Extract the corresponding rows from m and v\n",
    "        #                     m = optimizer.state[param]['exp_avg']\n",
    "        #                     v = optimizer.state[param]['exp_avg_sq']\n",
    "                            \n",
    "        #                     # Update the m and v values for the modified columns\n",
    "        #                     m[modified_columns] = 0  # Reset moving average for modified columns\n",
    "        #                     v[modified_columns] = 0  # Reset squared moving average for modified columns\n",
    "            \n",
    "        #     total_activations = torch.zeros(autoencoder.encoder.shape[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        # if ((i+2) % save_every ==0): # save periodically but before big changes\n",
    "        #     model_save_name = cfg.model_name.split(\"/\")[-1]\n",
    "        #     save_name = f\"{model_save_name}_sp{cfg.sparsity}_r{cfg.ratio}_{tensor_names[0]}_ckpt{num_saved_so_far}\"  # trim year\n",
    "    \n",
    "        #     # Make directory traiend_models if it doesn't exist\n",
    "        #     import os\n",
    "        #     if not os.path.exists(\"trained_models\"):\n",
    "        #         os.makedirs(\"trained_models\")\n",
    "        #     # Save model\n",
    "        #     torch.save(autoencoder, f\"trained_models/{save_name}.pt\")\n",
    "            \n",
    "        #     num_saved_so_far += 1\n",
    "    \n",
    "        # # Running sparsity check\n",
    "        # num_tokens_so_far = i*cfg.max_length*cfg.model_batch_size\n",
    "        # if(num_tokens_so_far > 200000):\n",
    "        #     if(i % 100 == 0):\n",
    "        #         with torch.no_grad():\n",
    "        #             sparsity = (c != 0).float().mean(dim=0).sum().cpu().item()\n",
    "        #         if sparsity > target_upper_sparsity:\n",
    "        #             cfg.l1_alpha *= (1 + adjustment_factor)\n",
    "        #         elif sparsity < target_lower_sparsity:\n",
    "        #             cfg.l1_alpha *= (1 - adjustment_factor)\n",
    "        #         # print(f\"Sparsity: {sparsity:.1f} | l1_alpha: {cfg.l1_alpha:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicated training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(cfg, autoencoder, storage_path, filename, layer):\n",
    "    model_save_name = cfg.model_name.split(\"/\")[-1]\n",
    "\n",
    "    # start_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # save_name = f\"{model_save_name}_sp{cfg.sparsity}_r{cfg.ratio}_{tensor_names[0]}_{start_time}\"  # trim year\n",
    "    storage_path_name = \"trained_models/\" + storage_path + f\"/layer_{layer}\"\n",
    "    # Make directory traiend_models if it doesn't exist\n",
    "    if not os.path.exists(storage_path_name):\n",
    "        os.makedirs(storage_path_name)\n",
    "    # Save model\n",
    "    filename = f\"L{layer}_{filename}\"\n",
    "    \n",
    "    torch.save(autoencoder, f\"{storage_path_name}/{filename}.pt\")\n",
    "    print(f\"Saved file at: {storage_path_name}/{filename}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
